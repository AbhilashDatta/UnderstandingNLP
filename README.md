# NLP-Notes:

[AI Hub](https://aihub.cloud.google.com/u/0/s)

Word Embedding:
* [What is Word Embedding](https://machinelearningmastery.com/what-are-word-embeddings/)

RNN Blogs:
* [sampling-strategies-for-recurrent-neural-networks](https://medium.com/machine-learning-at-petiteprogrammer/sampling-strategies-for-recurrent-neural-networks-9aea02a6616f)

LSTM:
* [Understanding LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [LSTM Implementation](https://mlexplained.com/2019/02/15/building-an-lstm-from-scratch-in-pytorch-lstms-in-depth-part-1/)
* [time-series-prediction-lstm-recurrent-neural-networks-python-keras](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)
* [time-series-forecasting-long-short-term-memory-network-python](https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/)
* [multivariate-time-series-forecasting-lstms-keras](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/)
* [multi-step-time-series-forecasting-long-short-term-memory-networks-python/](https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/)
* [Exploring LSTM](http://blog.echen.me/2017/05/30/exploring-lstms/)

Attention:

* [visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
